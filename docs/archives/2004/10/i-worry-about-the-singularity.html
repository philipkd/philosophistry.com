<title>I worry about the Singularity sometimes. (Philosophistry)</title>

<meta http-equiv="Content-Type" content="text/html; charset=UTF-8"/>

<link rel="stylesheet" href="/archives/styles.css" type="text/css" />


<center>

<div class="logo"><a href="/archives/"><img src="/archives/title.jpg"></a></div>
<div class="banner_container">
<div class="banner">This is <a href="/archives/">Philosophistry: The Blog</a>. There are other <a href="/">Philosophistry publications</a>.
</div>
</div>

</center>

<div class="content_container_container">
<div class="content_container">
<div class="content">

<script type="text/javascript"><!--
google_ad_client = "ca-pub-2773853926535023";
/* philosophistry rectangle */
google_ad_slot = "2022967402";
google_ad_width = 336;
google_ad_height = 280;
//-->
</script>
<script type="text/javascript"
src="http://pagead2.googlesyndication.com/pagead/show_ads.js">
</script>

<br/>

<script type="text/javascript">

  var _gaq = _gaq || [];
  _gaq.push(['_setAccount', 'UA-18069474-2']);
  _gaq.push(['_trackPageview']);

  (function() {
    var ga = document.createElement('script'); ga.type = 'text/javascript'; ga.async = true;
    ga.src = ('https:' == document.location.protocol ? 'https://ssl' : 'http://www') + '.google-analytics.com/ga.js';
    var s = document.getElementsByTagName('script')[0]; s.parentNode.insertBefore(ga, s);
  })();

</script>

<br/>

<h1>I worry about the Singularity sometimes.</h1>
<h2>by <a href="mailto:philblog@dhingra.org">phil</a> on Wednesday Oct 13, 2004  1:00 AM 
<br><a href="/archives/singularity.html">Singularity</a></h2>

<p>Ray Kurzweil says that the biggest challenge for society as we approach the Singularity will be defining what it means to be human.</p>

<p>Heh, yeah right.  I really doubt that the semantics of the word "human" will really bother anybody.  Derrida and his gang of deconstructionist obfuscators have already shown how easy it is to skewer words and have nobody blink their eye.</p>

<p>People will treat humans as humans in a "I know it when I see it" kind of fashion.  And the fact of the matter is, people have had a broad spectrum of what they treat as human for the longest time.  Our American founding fathers treated people who were born south of the equator inbetween the Atlantic Ocean and the Indian Ocean who also happened to have an evolutionarily beneficial, but darker, pigmentation in their skin, as <i>not</i> human; i.e. slaves.</p>

<p>I think the questions that will come up is how humans, when granted enlightened thinking by machines, will be able to stand on the crutches of traditional human illusions.</p>

<p>For example, Nietzsche announced "God is dead."  But I don't think everybody got the memo.</p>

<p>But, in the Singularity, once everybody is given the computing power of a billion Pentiums, they will be able to digest all of the human knowledge in the timespan of a hic-cup, and then get Nietzsche's news.  Okay, perhaps this is not a problem because there are many atheists out there who are doing fine without God--or are they?  Many studies show that religious faith is highly correleated with happiness.</p>

<p>But what about other illusions, like time, existence, love, purpose.</p>

<p>How will we react when we have a true understanding that time doesn't really exist, and that cause and effect is just a trick of perception, will we cease to treat things the way we treat them?  Will we fear death like we used to?  Will death even matter?</p>

<p>I guess the answer to those questions is, "it depends on how internalized the knowledge becomes."  If we are able to process and deal w/ knowledge in a cold fashion, maybe it won't bother us like it doesn't bother intellectuals now--or does it?  I read some of <i>Consciousness Explained</i> from Daniel Dennet, and I had to put it aside because I was seriously starting to lose my mind.</p>

<p>Or another problem in the Singularity is when we have absolute power to control our own emotions.  Would we just shut off all pain?  Maybe you would say, "but I'll always retain free will, and so I wouldn't choose to shut off all pain." But what if you could shut off your care of free will?  "But I wouldn't shut it off."  But you would be so smart to know that after you have shut off your care for free will, you wouldn't have any regret, and therefore it is a rational choice.  In other words, what is to stop us from ending up in stable equilibrium of being a vegetable in bliss?  Would there be safegaurds against it?</p>

<p>I still fantasize a bit about the Singularity and all the cool things I'll be able to do while in it, but to be realistic, I'd say that the Singularity may very well be just one big death.  I'm not talking about a physical death, but a pandemic death on every human-laden concept.  Even death will die.  Life probably won't mean anything to us.  Even the notion of "us" and "meaning" will dissolve.</p>

<p>My biggest worry in the Singularity is <i>total dissolution</i>.  But then I temper that worry with the trust that even worriment itself will be dissolved.  Yipes!<br />
<h2>Comments</h2><p>Julie said on October 18, 2004  2:21 PM: <p>Hello!<br />
I'm French. I don't understand everything you write, maybe only a half(!), not because of WHAT you write, but because of my bloody poor knowledge about your language... I feel so frustrated! Because the half I can guess is fascinating. This experience gives me a lesson of humility, and the motivation to improve my understanding of American English... At least I'll make you smile with my babblings.<br />
Byyyyyye!</p></p>
<p><a title="http://halfburntout.blogdrive.com" href="http://halfburntout.blogdrive.com" rel="nofollow">Josh</a> said on October 29, 2004  5:19 PM: <p>Good brainstorming, Phil. Just remember though: none of this will matter when it actually happens, so just don't worry about it. The funny thing about the Singularity is that there is always speculation and questions raised about it. That post could have went on for years. Good luck with it.</p></p>
<p>james said on January  4, 2005 12:18 PM: <p>You're kidding right? You're concerned with a phenomonological event that some human has conceived of but of which nothing is empirically known, and in fact, which may not occur?</p>

<p>You must be very young and naive.</p></p>
<p><a title="http://www.philosophistry.com/" href="http://www.philosophistry.com/" rel="nofollow">Philip Dhingra</a> said on January  4, 2005  2:12 PM: <p>In response to james.</p>

<p>I first learned about the Singularity concept in Jan. of 2002 (3 years ago).  Since then, I've had my doubts about the theory.  Some of those doubts pointed to my youth and naievete as possible culprits yes.  But still, over that time, those doubts have been overcome, and I still remain a strong believer in the inevitability of the Singularity.</p>

<p>I know this doesn't suffice as proof, but it doesn't look like you were trying to start a serious argument.</p></p>
<p>Gary said on January  7, 2005 12:27 AM: <p>You donâ€™t have to worry about purposelessness and blissful dissolution, because my singularity bots will eat yours up for spare parts.  We have a purpose which along the way will give you a purpose: food.  Don't worry, see you on the other side!</p></p>


<br/> 
<a rel="license" href="http://creativecommons.org/licenses/by/2.0/"><img alt="Creative Commons License" style="border-width:0" src="http://i.creativecommons.org/l/by/2.0/80x15.png" /></a>


</div> <!-- content -->


</div> <!-- content_container -->
</div> <!-- content_container_container -->